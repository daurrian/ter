\documentclass[../../rapport.tex]{subfiles}

\begin{document}
  Pour construire un nouveau type à partir d'autres, on doit donner 3 règles :
  \begin{itemize}
    \item \textbf{Formation du type}, qui permet de construire un type à partir d'autres types ou famille de types,
    \item \textbf{Introduction}, qui explique comment sont construits les éléments de ce type,
    \item \textbf{Élimination}, décrivant comment utiliser ces éléments.
  \end{itemize}

  Partant de ces 3 règles, on peut construire un type et éventuellement ajouter des règles supplémentaires concernant
  leur comportement par rapport à l'égalité par définition.

  \subsubsection{Univers}

  Plus tôt, on a utilisé un jugement de la forme "$\Gamma \vdash A\ \text{type}$" pour signifier que $A$ est un type.
  Cependant ce jugement n'est pas un jugement de la théorie, on se ramène alors à un autre jugement déjà présent :
  le jugement de typage.
  Pour ce faire, on doit introduire un type composé de type, un type univers $\U$.
  Pour la même raison, on voudrais dire que $\U$ est lui-même un élément d'un type plus grand et ainsi de suite.
  Pour résoudre ce problème, on postule qu'il existe une hiérarchie de type
  $$\U_0,\ \U_1,\ \U_2,\ \hdots,\ \U_i,\ \hdots$$
  telle que $\U_i : \U_{i+1}$.

  Pour ces types, on a seulement une règle d'introduction et une règle décrivant la hiérarchie entre ces types :

  $$
  \begin{array}{cc}
    \prftree[r]{($\U$ i)}{\Gamma \ctx}{\Gamma \vdash U_i : U_{i+1}} \hspace{2cm}
    & \prftree[r]{($\U$ cumul)}{\Gamma \vdash A : \U_i}{\Gamma \vdash A : \U_{i+1}}
  \end{array}
  $$

  Par conséquent, la règle sur les contextes devient la suivante :

  $$
  \prftree[r]{($\ctx$)}{(a_1 : A_1, \hdots, a_{n-1} : A_{n-1}) \vdash A_n : \U_k}
    {(a_1 : A_1, \hdots, a_n : A_n) \ctx}
  $$

  \subsubsection{Fonctions}

  Étant donné deux types $A, B : \U$, on peut former le type des fonctions de $A$ dans $B$ noté $A \fun B$
  grâce à la règle de formation suivante :

  $$
  \prfinterspace=2em
  \prftree[r]{($\fun$ f)}{\Gamma \vdash A : \U_i}{\Gamma \vdash B : \U_i}{\Gamma \vdash A \fun B : \U_i}
  $$

  Une fonction est donc un élément $f$ de type $A \fun B$.
  Si on se donne $a : A$, on peut évaluer $f$ en $a$ ce qui donne un élément de type $B$
  que l'on note $f\ a$ ou bien $f(a)$ qui est appelé valeur de $f$ en $a$, c'est la règle d'élimination de $\fun$ :

  $$
  \prfinterspace=2em
  \prftree[r]{($\fun$ e)}{\Gamma \vdash f : A \fun B}{\Gamma \vdash a : A}{\Gamma \vdash f\ a : B}
  $$

  Pour former une fonction $f$ de $A$ dans $B$ \textit{ie.} un élément de type $A \fun B$,
  la manière canonique de faire est d'utiliser les $\lambda$-abstraction et la règle d'introduction suivante :

  $$
  \prftree[r]{($\fun$ i)}{\Gamma, x : A \vdash \Phi : B}{\Gamma \vdash \lambda (x : A). \Phi : A \fun B}
  $$
  Dans cette règle $\Phi$ correspond à une formule qui peut éventuellement faire intervenir la variable $x$.

  Enfin, lorsque l'on considère une fonction $f : A \fun B$ définie par $f :\equiv \lambda (x : A). \Phi$
  où $\Phi$ est une formule et un élément $a : A$, il est naturel que la valeur de $f$ en $a$ soit égale à
  la formule $\Phi$ où l'on remplace les occurences de $x$ par des $a$, ce que l'on note $\Phi[a/x]$.
  Ce comportement est en fait une règle d'égalité que l'on peut énoncer sous cette forme :

  $$
  \prfinterspace=2em
  \prftree[r]{($\beta$)}{\Gamma, x : A \vdash \Phi : B}{\Gamma \vdash a : A}
    {\Gamma \vdash (\lambda(x : A).\Phi)\ a \equiv \Phi[a/x]}
  $$

  \begin{example}
    Considérons un type $A : \U$ et la fonction "identité" de $A$ définie par $I :\equiv \lambda(x : A).x$.
    Pour prouver que le type de $I$ est bien $A \fun A$, on peut utiliser les règles énoncées précédemment :

    $$
    \prftree
      {\prftree
	{\prfaxiom{A : \U \vdash A : \U}}
	{A : \U, x : A \vdash x : A}}
      {A : \U \vdash \lambda(x : A). x : A \fun A}
    $$
  \end{example}

  On a vu jusqu'ici comment construire des fonctions à une variable, on peut alors généraliser pour obtenir
  des fonctions à plusieurs variables.
  Pour ce faire, considérons trois types $A, B, C : \U$.
  Naïvement, on voudrais construire une fonction de type $A \times B \fun C$,
  mais le type $A \times B$ n'est pas encore défini.
  Pour contourner ce problème, on peut voir une fonction $f$ de $A \times B \fun C$ comme

  \begin{align}
    f(x, y) = (\lambda(a : A). f(a, y)) x &= ((\lambda(a : A). (\lambda(b : B). f(a, b)))\ x)\ y \\ 
					  &= (\lambda(a : A).\lambda(b : B). f(a, b))\ x\ y.
  \end{align}

  On a ainsi obtenu une fonction de type $A \fun B \fun C$ qui prend les mêmes valeurs que $f$
  grâce à ce processus de \textit{curryfication}.

  \begin{example}
    Considérons deux types $A, B : \U$ et la fonction $K$ définie par
    $$K :\equiv \lambda(x : A).(\lambda(y : B).x)$$
    Grâce à un arbre similaire au précédent, on trouve que le type de $K$ est $A \fun B \fun A$
    (on omet les parenthèses en prenant comme convention que $A \fun A \fun A$ est égal à $A \fun (A \fun A)$).
    De plus, on peut également montrer que si $a : A$ et $b : B$, alors $K\ a\ b \equiv a$. En effet, \textsc{A faire.}
    % $$
    % \prfinterspace=2em
    % \prftree{}
    % $$
  \end{example}

  Si on considère deux types $A, B : \U$ et qu'on les voit comme des propositions,
  alors le type $A \fun B$ peut s'interpreter comme l'implication $A \implies B$.

  \subsubsection{Fonctions dépendantes ($\Pi$-type)}

  Une manière de généraliser le type des fonctions est de définir un type de fonctions dépendantes (ou $\prod$-type),
  qui est un type de fonction dont le codomaine dépend du point d'application de la fonction.

  Pour former ce nouveau type, on considère $A : \U$ un type et $B : A \fun \U$ une famille de type indexée sur $A$.
  On peut alors former le type $\prod_{a : A}{B(a)}$ grâce à la règle de formation suivante : \textsc{Revoir avec univers}

  $$
  \prfinterspace=2em
  \prftree[r]{($\Pi$ f)}{\Gamma \vdash A : \U_i}{\Gamma, a : A \vdash B(a) : \U_i}
    {\Gamma \vdash \prod_{a:A}{B(a)} : \U_i}
  $$

  On construit des éléments de type $\prod_{a:A}{B(a)}$ de manière analogue aux fonctions en utilisant des $\lambda$-abstractions.
  En effet, $\lambda(a : A). \Phi$ est de type $\prod_{a:A}{B(a)}$ si lorsque $a : A$, alors $\Phi : B(x)$.
  Cette règle énoncé plus formellement est la règle d'introduction de ce nouveau type :

  $$
  \prftree[r]{($\Pi$ i)}{\Gamma, a : A \vdash \Phi : B(a)}
    {\Gamma \vdash \lambda(a : A). \Phi : \prod_{a:A}{B(a)}}
  $$

  Ensuite, la règle d'élimination est similaire à celle des types de fonctions.
  Si on considère $f : \prod_{a:A}B(a)$ et $a : A$, alors $f\ a$ est de type $B(a)$,
  ce que l'on peut traduire avec la règle suivante :

  $$
  \prfinterspace=2em
  \prftree[r]{($\Pi$ e)}{\Gamma \vdash f : \prod_{a:A}{B(a)}}{\Gamma \vdash a : A}
    {\Gamma \vdash f\ a : B(a)}
  $$

  Également, la règle $\beta$ des fonctions se généralise au $\prod$-type :

  $$
  \prfinterspace=2em
  \prftree[r]{($\beta$)}{\Gamma, x : A \vdash \Phi : B(x)}{\Gamma \vdash a : A}
    {\Gamma \vdash (\lambda(x : A).\Phi)\ a \equiv \Phi[a/x]}
  $$

  L'utilité des types de fonctions dépendantes est notamment de pouvoir définir des fonctions de façon polymorphes,
  comme le montre les exemples suivants.

  \begin{example}
    La fonction identité du paragraphe précédent était défini sur un type $A : \U$ quelconque.
    On peut alors généraliser sa définition de la manière suivante :

    $$I \equiv \lambda (A : \U). \lambda (a : A).\ a : \prod_{A : \U}{A \fun A}.$$
    Ainsi définie, la fonction $I$ ne dépend pas d'un type préexistant.

    On peut également redéfinir la fonction constante $K$ d'une manière analogue :

    $$K \equiv \lambda (A : \U). \lambda (B : \U). \lambda (x : A). \lambda (y : B).\ x :
      \prod_{A : \U}\prod_{B : \U}{A \fun B \fun A}.$$

    Pour ces types et définition polymorphe, on peut également avoir la notation $I_A$ à la place de $I\ A$
    pour plus de clarté.
  \end{example}

  D'un autre point de vue ce type peut également être vu comme l'équivalent du $\forall$ de la logique
  du première ordre.
  En effet, si on considère $A : \U$ un type et $C : A \fun \U$ une famille de type,
  que l'on peut également voir comme un prédicat, alors le type $\prod_{a : A}{C(a)}$ se comporte comme
  la proposition $\forall a,\ C(a)$ en logique classique.

  \subsubsection{Type vide}

  On introduit le type vide $\0$, qui ne contient aucun élément et donc n'a pas de règle d'introduction mais seulement
  une régle de formation et d'élimination :

  $$
  \prfinterspace=2em
  \begin{array}{cc}
    \prftree[r]{($\0$ i)}{\Gamma \ctx}{\Gamma \vdash \0 : \U_i} \hspace{2cm}
    & \prftree[r]{($\0$ e)}{\Gamma, x : \0 \vdash C : \U_i}{\Gamma \vdash a : \0}{\Gamma \vdash \rec_{\0}(C, a) : C}
  \end{array}
  $$

  Ainsi, on a construit une fonction $\rec_{\0}$ de type $\prod_{C: \U} \0 \fun C$
  qui à un type $C : \U_i$ associe une fonction qui ne prend aucune valeur.

  \subsubsection{Type unité}

  \subsubsection{Types inductifs : W-types}

  Pour construire le type des entiers $\N$, les constructeurs précédent ne suffisent pas car ils ne permettent
  pas de décrire le caractère inductif des entiers.
  Habituellement, on définit le type $\N$ comme étant un élément $0 : \N$ et une fonction successeur
  $s : \N \fun \N$ et un entier est de la forme $0$ ou bien $s\circ s \circ \hdots \circ s\ 0$.
  Une autre manière de le voir est de décrire $\N$ comme un arbre dont $0$ est une feuille et
  chacun des noeuds est d'arité un (\textit{ie.} possède au plus un fils).

  \begin{figure}[ht]
    \centering
  \begin{tikzpicture}
  \node {0} [grow=right]
    child {node {1}
      child {node {2}
	child {node {$\hdots$}}
      }
    };
  \end{tikzpicture}
  \end{figure}

  Un autre exemple de type défini de manière inductive est le type $L(A)$ des listes sur un type $A : \U$.
  La seule feuille est la liste vide notée $()$ et la fonctions jouant le rôle de constructeur inductif est
  la fonction $c : A \fun L(A) \fun L(A)$ qui a un élément $a : A$ et une liste $l : L(A)$ renvoie la liste
  dont le premier élément est $a$ et le reste est $l$.
  Ainsi, toutes les listes sont de la forme $() : L(A)$ ou bien $c\ a_1\ (c\ a_2\ (\hdots (c\ a_n\ ()))) :L(A)$.

  \begin{figure}[ht]
    \centering
  \begin{tikzpicture}
    [
	level 1/.style={sibling distance=12mm},
	level 2/.style={sibling distance=6mm},
	level 3/.style={sibling distance=3mm}
    ]
  \node {()} [grow=right]
    child {node {(0)}
      child {node {(00)} child {node {$\hdots$}} child {node {$\hdots$}}}
      child {node {(01)} child {node {$\hdots$}} child {node {$\hdots$}}}
    }
    child {node {(1)}
      child {node {(10)} child {node {$\hdots$}} child {node {$\hdots$}}}
      child {node {(11)} child {node {$\hdots$}} child {node {$\hdots$}}}
    };
  \end{tikzpicture}
  \end{figure}

  Pour généraliser les types inductifs, on introduit alors les W-types (\textit{well-founded trees}) de Martin-Löf.
  Pour ce faire, on utilise un type $A : \U$ qui correspond aux \textit{étiquettes} et un type $B : A \fun \U$ qui
  permet de coder l'arité des noeuds : un noeud dont l'étiquette est $a : A$ aura une arité de $B(a)$.
  Le type résultant de ces deux types est $W_{a:A} B(a)$ que l'on construit via la règle de formation suivante :

  $$
  \prfinterspace=2em
  \prftree[r]{(W f)}{\Gamma \vdash A : \U}{\Gamma, a : A \vdash B(a) : \U}{\Gamma \vdash W_{a: A} B(a) : \U}
  $$

  Les éléments d'un type $W_{a:A}B(a)$ sont donc des noeuds d'un arbre auxquels on associe la fonction donnant
  les noeuds précédents dans l'arbre. On construit ces éléments à l'aide
  de la règle d'introduction pour les W-types :

  $$
  \prfinterspace=2em
  \prftree[r]{(W i)}{\Gamma \vdash a : A}{\Gamma, a : A \vdash b : B(a) \fun W_{x:A}B(x)}
    {\Gamma \vdash \sup(a, b) : W_{x:A}B(x)}
  $$
  La fonction $\sup$ utilisé dans cette règle est donc de type
  $$\sup : \prod_{a:A}{\left(B(a) \fun W_{x:A}B(x)\right)} \fun W_{a:A}B(a).$$
  Chaque noeud $c :\equiv \sup(a, b) : W_{x:A}B(x)$ est donc relié aux autres par la fonction $b : B(a) \fun W_{x:A}B(x)$,
  en effet si on considère un élément $v : B(a)$ alors $b\ v$ est un prédecesseur du noeud $c$ dans l'arbre $W_{x:A}B(x)$.

  \begin{figure}[ht]
    \centering
    \begin{tikzpicture}
      [
	level 1/.style={sibling distance=25mm},
	level 2/.style={sibling distance=15mm}
      ]
      \node {$\sup(a_1, b_1)$} [grow=down]
	child {node {$b_1\ v_1 = \sup(a_2, b_2)$}
	  child {node {$b_2\ v_2$} edge from parent node[left] {$v_2$}}
	  child {node {$\hdots$}}
	  edge from parent node[left] {$v_1\ $}
	}
	child {node {$\hdots$}}
	child {node {$\hdots$}}
	child [grow=north east] {node {$\hdots$}};
    \end{tikzpicture}
  \end{figure}

  Reprenons l'exemple du type $\N$ des entiers.
  On peut le décrire en terme de W-type en prenant $\N :\equiv W_{x: \textbf{2}}B(x)$ où $B(0_{\textbf{2}}) :\equiv \textbf{0}$
  et $B(1_{\textbf{2}}) :\equiv \textbf{1}$.
  En effet, il y a deux manières de construire un entier : ou bien c'est 0 ou bien il est de la forme $s\ k$ avec $k : \N$.
  Pour 0, son étiquette dans l'arbre est donc $0_{\textbf{2}}$ tandis que les éléments de la forme $s\ k$ ont l'étiquette
  $1_{\textbf{2}}$.
  On peut donc écrire 0 avec la fonction $\sup$ :
  $$ 0 :\equiv \sup(0_{\textbf{2}}, \rec_{\textbf{0}, \N}).$$
  De même la fonction successeur $s : \N \fun \N$ peut être définie de la manière suivante :
  $$ s :\equiv \lambda n.\ \sup(1_{\textbf{2}}, \lambda(x : \textbf{1}).\ n) : \N \fun \N.$$
  Et donc on a $1 :\equiv s\ 0 \equiv \sup(1_{\textbf{2}}, \lambda x.\ 0)$ etc.

  La règle d'élimination décrit le principe d'induction sur les W-types.
  Pour prouver une proposition sur un type inductif, de manière analogue au principe de récurrence des entiers,
  on montre que la proposition est héréditaire, dans le cas présent cela revient à montrer que si la proposition est vraie
  sur tout les sous-arbres, alors elle est vraie sur le noeud reliant ces sous-arbres, c'est ce que dit la dernière prémisse
  de la règle d'élimination, qui s'énonce de la manière suivante :

  $$
  \prfinterspace=2em
  \prftree[r]{(W e)}
  {\Gamma\ \vdash t : W_{x:A}B(x)}
  {
    \prfStackPremises
    % {\Gamma \vdash t : W_{x:A}B(x)}
    {\Gamma, a : A, b : B(a) \fun W_{x:A}B(x),}
    {c : \prod_{v:B(a)}{E(b\ v)}\ \vdash e(a, b, c) : E(\sup(a, b))}
  }
    % {\Gamma, a : A, b : B(a) \fun W_{x:A}B(x), c : \prod_{v : B(a)}{E(f\ v)} \vdash e(a, b, c) : E(\sup(a, b))}
  {\Gamma\ \vdash \rec_{W_{x:A}B(x)}(E, e, t) : E(t)}
  $$
  La fonction $e$ présente dans la règle est de type
  $$e \colon \prod_{a:A}\prod_{b:(B(a) \fun W_{x:A}B(x))}\left(\prod_{v:B(a)}E(b\ v)\right) \fun E(\sup(a, b)).$$
  et pour des éléments $a : A$, $b : B(a) \fun W_{x:A}B(x)$ et une preuve $c$ de $\prod_{v:B(a)}{E(b\ v)}$
  renvoie une preuve de $E(\sup(a, b))$.
  La fonction $\rec_{W_{x:A}B(x)}$ présente dans la conclusion de la règle précédente est une fonction qui à un prédicat
  (ou famille de type) $E$ sur le type $W_{x:A}B(x)$, une fonction $e$ comme décrit juste avant et un élément $t : W_{x:A}B(x)$
  retourne une preuve (ou un élément) de $E(t)$. Ainsi, la fonction $e$ et la fonction $\rec_{W_{x:A}B(x)}$ renvoie des preuves de même nature,
  on peut donc imaginer une relation liant les deux : c'est la règle d'égalité (ou règle de calcul de $\rec_{W_{x:A}B(x)}$).

  $$
  \prfinterspace=2em
  \prftree[r]{(W $\equiv$)}
    {\prfStackPremises
      {\Gamma\ \vdash a : A}
      {\Gamma\ \vdash b : B(a) \fun W_{x:A}B(x)}
      {\Gamma, x : A, x : B(x) \fun W_{x:A}B(x), z : \prod_{v:B(x)}{E(y\ v)}\ \vdash e(x, y, z) : E(\sup(x, y))}
    }
      {\Gamma \vdash \rec_{W_{x:A}B(x)}(E, e, \sup(a, b)) \equiv e(a, b, \lambda v.\ \rec_{W_{x:A}B(x)}(E, e, b\ v)) : E(\sup(a, b))}
  $$

  En effet, pour $a : A$ et $b : B(a) \fun W_{x:A}B(x)$ la fonction $\lambda(v : B(a)).\ \rec_{W_{x:A}B(x)}(E, e, b\ v)$
  retourne une preuve (un élément) de $\prod_{v : B(a)}{E(b \ v)}$, ce qui correspond au
  dernier paramètre de la fonction $e$ et donc le membre de droite de l'égalité est bien une preuve (un élément)
  de $E(\sup(a, b))$ comme voulue.
  Les prémisses de cette règle sont de simple vérifications de typage de $a$, $b$ et $e$.

  \subsubsection{Entiers naturels}

  Avec les W-types, nous pouvons désormais construire les entiers naturels.
  Pour ce faire, on note $\N \equiv W_{x : \2}B(x)$ où $B(0_{\2}) :\equiv \0$ et $B(1_{\2}) :\equiv \1$.
  On a donc déjà vu dans le paragraphe précédent que tout élément de $\N$ s'exprime sous la forme $0$ ou $s\ k$
  avec $k : \N$ et de plus on avait les expressions de $0$ et de $s : \N \fun \N$ suivantes :
  $$\left\{ \begin{array}{rll}
      0 &:\equiv \sup(0_{\2}, \rec_{\0, \N}) 				&: \N \\
      s &:\equiv \lambda(n : \N).\ \sup(1_{\2}, \lambda(x : \1).\ n)	&: \N \fun \N
  \end{array}\right.$$

  On peut également réexprimer les règles de formation, d'introduction, d'élimination et d'égalité dans le cas de $\N$.
  Pour la règle de formation, on obtient :

  $$
  \prfinterspace=2em
  \prftree
    {\prfaxiom{\Gamma\ \vdash \2 : \U}}
    {\prftree
      {\prfaxiom{\Gamma, a : \2\ \vdash B : \2 \fun \U}}
      {\prftree
	{\prfaxiom{\Gamma\ \vdash \2 : \U}}
      {\Gamma, a : \2\ \vdash a : \2}}
    {\Gamma, a : \2\ \vdash B(a) : \U}}
  {\Gamma\ \vdash \N : \U}
  $$

  On a donc la règle simplifiée :

  $$
  \prfbyaxiom{$\N$ i}
    {\Gamma\ \vdash \N : \U}
  $$

  Ensuite, concernant la règle d'introduction on distingue deux cas puisqu'il y a deux manières de construire
  un élément $n : \N$, soit $n \equiv 0$, soit $n \equiv s\ k$ avec $k : \N$.

  $$
  \prfinterspace=2em
  \prftree
    {\prftree
      {\prfaxiom{\Gamma\ \vdash 0_{\2} : \2}}
      {\prftree
	{\prfaxiom{\Gamma, 0_{\2} : \2\ \vdash \rec_{\0, \N} : \0 \fun \N}}
      {\Gamma, 0_{\2} : \2\ \vdash \rec_{\0, \N} : B(0_{\2}) \fun \N}}
    {\Gamma\ \vdash \sup(0_{\2}, \rec_{\0, \N}) : \N}}
  {\Gamma\ \vdash 0 : \N}
  $$

  $$
  \prfinterspace=2em
  \prftree
    {\prfaxiom{\Gamma\ \vdash s : \N \fun \N}}
    {\Gamma\ \vdash k : \N}
  {\Gamma \vdash s\ k : \N}
  $$
  Ce qui donne les deux règles d'introduction de $\N$ :
  $$\begin{array}{cc}
    \prfbyaxiom{($0$ i)}{\Gamma\ \vdash 0 : \N}\hspace{2cm} & \prftree[r]{($s$ i)}{\Gamma\ \vdash k : \N}{\Gamma\ \vdash s\ k : \N}
  \end{array}$$

  Pour la règle d'élimination sur le type $\N$, on s'attend à retrouver le principe de récurrence usuel sur les entiers,
  à savoir que si une prédicat $E : \N \fun \U$ est vrai sur $0$ et que si $E(k)$ est vrai alors $E(s\ k)$ est vrai,
  alors $E(k)$ est vrai sur tout $k : \N$.
  $$
  \prfinterspace=2em
  \prftree
    {\Gamma\ \vdash k : \N}
    {\prftree
      {\vdash \text{cas où $a = 0_{\2}$}}
      {\vdash \text{cas où $a = 1_{\2}$}}
    {\Gamma, a : \2, b : B(a) \fun \N, c : \prod_{v : B(a)}{E(b\ v)}\ \vdash e(a, b, c) : E(\sup(a, b))}}
    {\Gamma\ \vdash \rec_{\N}(E, e, k) : E(k)}
  $$

  D'un point de vue moins formel, pour prouver que $\rec_{\N}(E, e, k)$ est une preuve de $E(k)$,
  il faut d'abord vérifier le typage $k : \N$, puis que lorsque l'on considère $\sup(a, b) : \N$ avec
  $a : \2$, $b : B(a) \fun \N$ et $c : \prod_{v : B(a)}{E(b\ v)}$ alors $e(a, b, c)$ est une preuve de $E(\sup(a, b))$.
  Pour ce faire, on distingue deux cas : si $a \equiv 0_{\2}$ et si $a \equiv 1_{\2}$.
  \begin{itemize}
    \item Dans le premier cas, on a $b : \0 \fun \N$ donc $b \equiv \rec_{\0, \N}$ et $c : \prod_{v:\0}{E(b\ v)}$.
      Ainsi, $e(0_{\2}, b, c) : E(\sup(0_{\2}, \rec_{\0,\N})) \equiv E(0)$. On doit alors montrer $E(0)$.
    \item Dans le cas $a \equiv 1_{\2}$, on a $b : \1 \fun \N$ donc $b$ est une constante égale à $b\ \0_{\1}$ et
      $c : \prod_{v : \1}{E(b\ v)} \equiv E(b\ 0_{\1})$.
      Donc en posant $k \equiv b\ 0_{\1}$, on a
      $$e(a, b, c) \equiv e(1_{\2}, \lambda(x : \1).\ k, c) : E(\sup(1_{\2}, \lambda(x : \1).\ k)) \equiv E(s\ k),$$
      et $c : E(k)$.
      Finalement, le cas $a \equiv 1_{\2}$ est l'hérédité : sous l'hypothèse $E(k)$, on montre $E(s\ k)$
  \end{itemize}
  On retrouve bien le principe de récurrence usuel.

\end{document}
